h1_h2 (512, 512)
h2_h3 (256, 512)
h3_h4 (128, 256)
h4_y (32, 128)
x_h1 (512, 448)
epoch 0
	Accuracy of training:  0.19697265625
	Loss of training:  0.824463374462
epoch 1
	Accuracy of training:  0.146923828125
	Loss of training:  0.707608709739
epoch 2
	Accuracy of training:  0.084375
	Loss of training:  0.68283588887
epoch 3
	Accuracy of training:  0.03125
	Loss of training:  0.664097397163
epoch 4
	Accuracy of training:  0.046875
	Loss of training:  0.650869441792
epoch 5
	Accuracy of training:  0.0625
	Loss of training:  0.641892686582
epoch 6
	Accuracy of training:  0.0640625
	Loss of training:  0.635756725097
epoch 7
	Accuracy of training:  0.0734375
	Loss of training:  0.630812771977
epoch 8
	Accuracy of training:  0.092236328125
	Loss of training:  0.62546517497
epoch 9
	Accuracy of training:  0.12041015625
	Loss of training:  0.618975784419
epoch 10
	Accuracy of training:  0.13603515625
	Loss of training:  0.611607127426
epoch 11
	Accuracy of training:  0.11416015625
	Loss of training:  0.606549053015
epoch 12
	Accuracy of training:  0.035986328125
	Loss of training:  0.604026079776
epoch 13
	Accuracy of training:  0.03134765625
	Loss of training:  0.604909333781
epoch 14
	Accuracy of training:  0.04853515625
	Loss of training:  0.608815952024
epoch 15
	Accuracy of training:  0.03603515625
	Loss of training:  0.609531995895
epoch 16
	Accuracy of training:  0.00947265625
	Loss of training:  0.604720974185
epoch 17
	Accuracy of training:  0.00791015625
	Loss of training:  0.600891432553
epoch 18
	Accuracy of training:  0.00947265625
	Loss of training:  0.594754533034
epoch 19
	Accuracy of training:  0.010986328125
	Loss of training:  0.588951053519
epoch 20
	Accuracy of training:  0.014111328125
	Loss of training:  0.586032778717
epoch 21
	Accuracy of training:  0.01572265625
	Loss of training:  0.585228723493
epoch 22
	Accuracy of training:  0.01416015625
	Loss of training:  0.586121052896
epoch 23
	Accuracy of training:  0.01572265625
	Loss of training:  0.588100042719
epoch 24
	Accuracy of training:  0.01884765625
	Loss of training:  0.589733723524
epoch 25
	Accuracy of training:  0.02041015625
	Loss of training:  0.588969652761
epoch 26
	Accuracy of training:  0.02041015625
	Loss of training:  0.588989062353
epoch 27
	Accuracy of training:  0.02041015625
	Loss of training:  0.589668173471
epoch 28
	Accuracy of training:  0.01728515625
	Loss of training:  0.595031395892
epoch 29
	Accuracy of training:  0.01572265625
	Loss of training:  0.592406771093
epoch 30
	Accuracy of training:  0.01103515625
	Loss of training:  0.591426068167
epoch 31
	Accuracy of training:  0.01416015625
	Loss of training:  0.604361196529
epoch 32
	Accuracy of training:  0.01552734375
	Loss of training:  0.586784883318
epoch 33
	Accuracy of training:  0.01259765625
	Loss of training:  0.587611517284
epoch 34
	Accuracy of training:  0.00947265625
	Loss of training:  0.57814141358
epoch 35
	Accuracy of training:  0.02197265625
	Loss of training:  0.571020141072
epoch 36
	Accuracy of training:  0.01572265625
	Loss of training:  0.586823014537
epoch 37
	Accuracy of training:  0.02041015625
	Loss of training:  0.597876382404
epoch 38
	Accuracy of training:  0.01572265625
	Loss of training:  0.576104871368
epoch 39
	Accuracy of training:  0.015673828125
	Loss of training:  0.625214146124
epoch 40
	Accuracy of training:  0.04853515625
	Loss of training:  0.62779366615
epoch 41
	Accuracy of training:  0.05947265625
	Loss of training:  0.648343604003
epoch 42
	Accuracy of training:  0.05947265625
	Loss of training:  0.626703162206
epoch 43
	Accuracy of training:  0.07197265625
	Loss of training:  0.638331513933
epoch 44
	Accuracy of training:  0.139111328125
	Loss of training:  0.624760082742
epoch 45
	Accuracy of training:  0.02041015625
	Loss of training:  0.621088237816
epoch 46
	Accuracy of training:  0.293798828125
	Loss of training:  0.60635223134
epoch 47
	Accuracy of training:  0.065673828125
	Loss of training:  0.580406678579
epoch 48
	Accuracy of training:  0.021875
	Loss of training:  0.550478512616
epoch 49
	Accuracy of training:  0.096875
	Loss of training:  0.551867985461
epoch 50
	Accuracy of training:  0.034423828125
	Loss of training:  0.62135343063
epoch 51
	Accuracy of training:  0.07666015625
	Loss of training:  0.635307939339
epoch 52
	Accuracy of training:  0.10947265625
	Loss of training:  0.654087205484
epoch 53
	Accuracy of training:  0.13134765625
	Loss of training:  0.669045500405
epoch 54
	Accuracy of training:  0.22197265625
	Loss of training:  0.665647190574
epoch 55
	Accuracy of training:  0.021875
	Loss of training:  0.658239720509
epoch 56
	Accuracy of training:  0.1931640625
	Loss of training:  0.685640587466
epoch 57
	Accuracy of training:  0.33603515625
	Loss of training:  0.677678510256
epoch 58
	Accuracy of training:  0.347021484375
	Loss of training:  0.678234718699
epoch 59
	Accuracy of training:  0.322021484375
	Loss of training:  0.682606793073
epoch 60
	Accuracy of training:  0.329833984375
	Loss of training:  0.687135066872
epoch 61
	Accuracy of training:  0.356396484375
	Loss of training:  0.691507149089
epoch 62
	Accuracy of training:  0.404833984375
	Loss of training:  0.694089409683
epoch 63
	Accuracy of training:  0.445361328125
	Loss of training:  0.698904221895
epoch 64
	Accuracy of training:  0.45322265625
	Loss of training:  0.70307916376
epoch 65
	Accuracy of training:  0.535986328125
	Loss of training:  0.704077817302
epoch 66
	Accuracy of training:  0.553173828125
	Loss of training:  0.704746793897
epoch 67
	Accuracy of training:  0.564111328125
	Loss of training:  0.705223669024
epoch 68
	Accuracy of training:  0.575048828125
	Loss of training:  0.705640312872
epoch 69
	Accuracy of training:  0.587548828125
	Loss of training:  0.706038256618
epoch 70
	Accuracy of training:  0.603173828125
	Loss of training:  0.706429393118
epoch 71
	Accuracy of training:  0.620361328125
	Loss of training:  0.706817378907
epoch 72
	Accuracy of training:  0.626611328125
	Loss of training:  0.707203303173
epoch 73
	Accuracy of training:  0.639111328125
	Loss of training:  0.707587695098
epoch 74
	Accuracy of training:  0.664111328125
	Loss of training:  0.707970869803
epoch 75
	Accuracy of training:  0.703173828125
	Loss of training:  0.708353861596
epoch 76
	Accuracy of training:  0.781298828125
	Loss of training:  0.70874086062
epoch 77
	Accuracy of training:  0.762548828125
	Loss of training:  0.709143650543
epoch 78
	Accuracy of training:  0.267236328125
	Loss of training:  0.709923247562
epoch 79
	Accuracy of training:  0.0
	Loss of training:  0.710057519894
epoch 80
	Accuracy of training:  0.470361328125
	Loss of training:  0.709861007764
epoch 81
	Accuracy of training:  0.396923828125
	Loss of training:  0.710821846558
epoch 82
	Accuracy of training:  0.184423828125
	Loss of training:  0.711188615789
epoch 83
	Accuracy of training:  0.626611328125
	Loss of training:  0.711217052833
epoch 84
	Accuracy of training:  0.820361328125
	Loss of training:  0.711698509712
epoch 85
	Accuracy of training:  0.85
	Loss of training:  0.712093903206
epoch 86
	Accuracy of training:  0.85
	Loss of training:  0.712468362279
epoch 87
	Accuracy of training:  0.85
	Loss of training:  0.712837138225
epoch 88
	Accuracy of training:  0.85
	Loss of training:  0.713203762064
epoch 89
	Accuracy of training:  0.85
	Loss of training:  0.713569062902
epoch 90
	Accuracy of training:  0.85
	Loss of training:  0.713933217881
epoch 91
	Accuracy of training:  0.85
	Loss of training:  0.714296345873
epoch 92
	Accuracy of training:  0.85
	Loss of training:  0.714658477204
epoch 93
	Accuracy of training:  0.85
	Loss of training:  0.715019647696
epoch 94
	Accuracy of training:  0.85
	Loss of training:  0.715379788581
epoch 95
	Accuracy of training:  0.85
	Loss of training:  0.715739003476
epoch 96
	Accuracy of training:  0.85
	Loss of training:  0.716097211867
epoch 97
	Accuracy of training:  0.85
	Loss of training:  0.716454479989
epoch 98
	Accuracy of training:  0.85
	Loss of training:  0.716810745536
epoch 99
	Accuracy of training:  0.85
	Loss of training:  0.717166100862
epoch 100
	Accuracy of training:  0.85
	Loss of training:  0.717520485207
epoch 101
	Accuracy of training:  0.85
	Loss of training:  0.717873901356
epoch 102
	Accuracy of training:  0.85
	Loss of training:  0.718226376886
epoch 103
	Accuracy of training:  0.85
	Loss of training:  0.718577901222
epoch 104
	Accuracy of training:  0.85
	Loss of training:  0.7189284953
epoch 105
	Accuracy of training:  0.85
	Loss of training:  0.719278176891
epoch 106
	Accuracy of training:  0.85
	Loss of training:  0.719626894139
epoch 107
	Accuracy of training:  0.85
	Loss of training:  0.719974688761
epoch 108
	Accuracy of training:  0.85
	Loss of training:  0.720321617497
epoch 109
	Accuracy of training:  0.85
	Loss of training:  0.720667614002
epoch 110
	Accuracy of training:  0.85
	Loss of training:  0.721012678457
epoch 111
	Accuracy of training:  0.85
	Loss of training:  0.721356919949
epoch 112
	Accuracy of training:  0.85
	Loss of training:  0.721700215095
epoch 113
	Accuracy of training:  0.85
	Loss of training:  0.722042659449
epoch 114
	Accuracy of training:  0.85
	Loss of training:  0.722384207533
epoch 115
	Accuracy of training:  0.85
	Loss of training:  0.722724954883
epoch 116
	Accuracy of training:  0.85
	Loss of training:  0.723064824124
epoch 117
	Accuracy of training:  0.85
	Loss of training:  0.723403833422
epoch 118
	Accuracy of training:  0.85
	Loss of training:  0.723741985165
epoch 119
	Accuracy of training:  0.85
	Loss of training:  0.72407936235
epoch 120
	Accuracy of training:  0.85
	Loss of training:  0.724415876425
epoch 121
	Accuracy of training:  0.85
	Loss of training:  0.724751561647
epoch 122
	Accuracy of training:  0.85
	Loss of training:  0.725086444343
epoch 123
	Accuracy of training:  0.85
	Loss of training:  0.725420481781
epoch 124
	Accuracy of training:  0.85
	Loss of training:  0.72575374826
epoch 125
	Accuracy of training:  0.85
	Loss of training:  0.726086240407
epoch 126
	Accuracy of training:  0.85
	Loss of training:  0.726417866722
epoch 127
	Accuracy of training:  0.85
	Loss of training:  0.726748779335
epoch 128
	Accuracy of training:  0.85
	Loss of training:  0.727078889724
epoch 129
	Accuracy of training:  0.85
	Loss of training:  0.727408206736
epoch 130
	Accuracy of training:  0.85
	Loss of training:  0.727736739052
epoch 131
	Accuracy of training:  0.85
	Loss of training:  0.728064554819
epoch 132
	Accuracy of training:  0.85
	Loss of training:  0.728391622269
epoch 133
	Accuracy of training:  0.85
	Loss of training:  0.728717919032
epoch 134
	Accuracy of training:  0.85
	Loss of training:  0.729043472983
epoch 135
	Accuracy of training:  0.85
	Loss of training:  0.729368249059
epoch 136
	Accuracy of training:  0.85
	Loss of training:  0.729692346725
epoch 137
	Accuracy of training:  0.85
	Loss of training:  0.730015693285
epoch 138
	Accuracy of training:  0.85
	Loss of training:  0.730338310043
epoch 139
	Accuracy of training:  0.85
	Loss of training:  0.730660219584
epoch 140
	Accuracy of training:  0.85
	Loss of training:  0.730981424567
epoch 141
	Accuracy of training:  0.85
	Loss of training:  0.731301909429
epoch 142
	Accuracy of training:  0.85
	Loss of training:  0.731621729903
epoch 143
	Accuracy of training:  0.85
	Loss of training:  0.731940792245
epoch 144
	Accuracy of training:  0.85
	Loss of training:  0.732259218377
epoch 145
	Accuracy of training:  0.85
	Loss of training:  0.732576914172
epoch 146
	Accuracy of training:  0.85
	Loss of training:  0.732893968665
epoch 147
	Accuracy of training:  0.85
	Loss of training:  0.733210308367
epoch 148
	Accuracy of training:  0.85
	Loss of training:  0.733525955724
epoch 149
	Accuracy of training:  0.85
	Loss of training:  0.733840949758
epoch 150
	Accuracy of training:  0.85
	Loss of training:  0.734155251301
epoch 151
	Accuracy of training:  0.85
	Loss of training:  0.734468880598
epoch 152
	Accuracy of training:  0.85
	Loss of training:  0.73478186063
epoch 153
	Accuracy of training:  0.85
	Loss of training:  0.735094079725
epoch 154
	Accuracy of training:  0.85
	Loss of training:  0.735405655671
epoch 155
	Accuracy of training:  0.85
	Loss of training:  0.735716555663
epoch 156
	Accuracy of training:  0.85
	Loss of training:  0.736026724183
epoch 157
	Accuracy of training:  0.85
	Loss of training:  0.736336176889
epoch 158
	Accuracy of training:  0.85
	Loss of training:  0.736644912319
epoch 159
	Accuracy of training:  0.85
	Loss of training:  0.736952807993
epoch 160
	Accuracy of training:  0.85
	Loss of training:  0.737260028563
epoch 161
	Accuracy of training:  0.85
	Loss of training:  0.737566458166
epoch 162
	Accuracy of training:  0.85
	Loss of training:  0.737872091605
epoch 163
	Accuracy of training:  0.85
	Loss of training:  0.738177056878
epoch 164
	Accuracy of training:  0.85
	Loss of training:  0.738481368654
epoch 165
	Accuracy of training:  0.85
	Loss of training:  0.738785196451
epoch 166
	Accuracy of training:  0.85
	Loss of training:  0.739088598912
epoch 167
	Accuracy of training:  0.85
	Loss of training:  0.739391623531
epoch 168
	Accuracy of training:  0.85
	Loss of training:  0.739694333676
epoch 169
	Accuracy of training:  0.85
	Loss of training:  0.739996566856
epoch 170
	Accuracy of training:  0.85
	Loss of training:  0.740298336046
epoch 171
	Accuracy of training:  0.85
	Loss of training:  0.740599497966
epoch 172
	Accuracy of training:  0.85
	Loss of training:  0.740900020278
epoch 173
	Accuracy of training:  0.85
	Loss of training:  0.741199891909
epoch 174
	Accuracy of training:  0.85
	Loss of training:  0.741499115317
epoch 175
	Accuracy of training:  0.85
	Loss of training:  0.741797702678
epoch 176
	Accuracy of training:  0.85
	Loss of training:  0.742095734423
epoch 177
	Accuracy of training:  0.85
	Loss of training:  0.742393258767
epoch 178
	Accuracy of training:  0.85
	Loss of training:  0.742690323363
epoch 179
	Accuracy of training:  0.85
	Loss of training:  0.742987003538
epoch 180
	Accuracy of training:  0.85
	Loss of training:  0.743283227074
epoch 181
	Accuracy of training:  0.85
	Loss of training:  0.743579049269
epoch 182
	Accuracy of training:  0.85
	Loss of training:  0.74387448146
epoch 183
	Accuracy of training:  0.85
	Loss of training:  0.744169462862
epoch 184
	Accuracy of training:  0.85
	Loss of training:  0.744463977404
epoch 185
	Accuracy of training:  0.85
	Loss of training:  0.74475800473
epoch 186
	Accuracy of training:  0.85
	Loss of training:  0.745051565557
epoch 187
	Accuracy of training:  0.85
	Loss of training:  0.745344712265
epoch 188
	Accuracy of training:  0.85
	Loss of training:  0.745637398149
epoch 189
	Accuracy of training:  0.85
	Loss of training:  0.745929639041
epoch 190
	Accuracy of training:  0.85
	Loss of training:  0.746221499261
epoch 191
	Accuracy of training:  0.85
	Loss of training:  0.746512945875
epoch 192
	Accuracy of training:  0.85
	Loss of training:  0.746803938865
epoch 193
	Accuracy of training:  0.85
	Loss of training:  0.747094566782
epoch 194
	Accuracy of training:  0.85
	Loss of training:  0.747384814499
epoch 195
	Accuracy of training:  0.85
	Loss of training:  0.747674639302
epoch 196
	Accuracy of training:  0.85
	Loss of training:  0.747964041022
epoch 197
	Accuracy of training:  0.85
	Loss of training:  0.748253067496
epoch 198
	Accuracy of training:  0.85
	Loss of training:  0.748541707743
epoch 199
	Accuracy of training:  0.85
	Loss of training:  0.74882993538
174
317
0 0.993063429371
1 0.993063429371
2 0.993063429371
3 0.993064017966
4 0.993063667789
5 0.993062369525
6 0.993063405156
7 0.993063429371
8 0.993063570932
9 0.99306409061
10 0.993062498048
11 0.993063431233
12 0.993064247072
13 0.993062451482
14 0.993063414469
15 0.993063429371
16 0.993063429371
17 0.993063429371
18 0.993063429371
19 0.993063429371
20 0.993063434958
21 0.993063431233
22 0.993063429371
23 0.993063429371
24 0.993063429371
25 0.993063429371
26 0.993063429371
27 0.993063429371
28 0.993063429371
29 0.993063429371
30 0.993063429371
31 0.993063429371
32 0.993063429371
33 0.993063429371
34 0.993063429371
35 0.993063429371
36 0.993063429371
37 0.993063429371
38 0.993063526228
39 0.993063354865
40 0.993063427508
41 0.993063429371
42 0.993063429371
43 0.993063429371
44 0.993063429371
45 0.993064345792
46 0.993062430993
47 0.993063373491
48 0.993063429371
49 0.993063624948
50 0.993063228205
51 0.993063429371
52 0.993063429371
53 0.993063429371
54 0.993063524365
55 0.993063470349
56 0.993063271046
57 0.993063429371
58 0.993063429371
59 0.993063429371
60 0.993063429371
61 0.993063429371
62 0.993063431233
63 0.993063664064
64 0.993064012378
65 0.993062483147
66 0.99306344986
67 0.993064220995
68 0.993062378839
69 0.993063410744
70 0.993064343929
71 0.993063276634
72 0.993062362075
73 0.993064295501
74 0.993063403293
75 0.993062363937
76 0.993063405156
77 0.993064343929
78 0.993063265458
79 0.993062656373
80 0.993064103648
81 0.993062432855
82 0.993063341826
83 0.993063427508
84 0.993064293638
85 0.993062447757
86 0.993063416332
87 0.993063429371
88 0.993063431233
89 0.993063429371
90 0.993063429371
91 0.993063429371
92 0.993063669652
93 0.993064021692
94 0.993063272908
95 0.993062522262
96 0.993065133691
97 0.993061773479
98 0.993063466623
99 0.993064682931
100 0.993063671514
101 0.993061391637
102 0.993063539267
103 0.993064353243
104 0.993061110377
105 0.993062764406
106 0.993064858019
107 0.993062103167
108 0.993062224239
109 0.993063839152
110 0.993065377697
111 0.993063680828
112 0.993062080815
113 0.993064045906
114 0.993063122034
115 0.993062855676
116 0.99306280911
117 0.993062885478
118 0.993062732741
119 0.993062801659
120 0.993062797934
121 0.993062797934
122 0.993062797934
123 0.993062797934
124 0.993062797934
125 0.993062797934
126 0.993062797934
127 0.993062797934
128 0.993062797934
129 0.993062797934
130 0.993063200265
131 0.993063589558
132 0.993063047528
133 0.993062643334
134 0.993062797934
135 0.993062917143
136 0.993062859401
137 0.993062650785
138 0.993063293397
139 0.993063058704
140 0.993063010275
141 0.993063040078
142 0.993063207716
143 0.993064817041
144 0.993063606322
145 0.993063606322
146 0.993063574657
147 0.993063587695
148 0.993064003065
149 0.993064366281
150 0.993064232171
151 0.993063762784
152 0.993063429371
153 0.993063582107
154 0.993062281981
155 0.99306368269
156 0.993063665926
157 0.993063667789
158 0.993063665926
159 0.993063671514
160 0.993063667789
161 0.99306371063
162 0.993064545095
163 0.993062622845
164 0.993063651025
165 0.993063865229
166 0.993064343929
167 0.993063546717
168 0.993063524365
169 0.993063524365
170 0.993063524365
171 0.993063524365
172 0.993062622845
173 0.993063651025
174 0.993064580485
175 0.99306354858
176 0.993062701076
177 0.993064496666
178 0.993063505739
179 0.993063524365
180 0.993063524365
181 0.993063524365
182 0.993062622845
183 0.993064565584
184 0.99306354858
185 0.993063524365
186 0.993062820286
187 0.993063561618
188 0.993063507602
189 0.993064010516
190 0.993064185604
191 0.993063429371
192 0.993062783033
193 0.993064489216
194 0.993062706664
195 0.993064237759
196 0.993063820526
197 0.993062917143
198 0.993063302711
199 0.993063712493
200 0.993063928559
201 0.993063447997
202 0.993064254522
203 0.993063019589
204 0.993062945083
205 0.993063956499
206 0.993063846603
207 0.993063118309
208 0.99306451343
209 0.993062410504
210 0.993063349277
211 0.99306354858
212 0.993063734844
213 0.993063192815
214 0.993063429371
215 0.993063429371
216 0.993063431233
217 0.993063429371
218 0.993064343929
219 0.993062371388
220 0.993063405156
221 0.993064345792
222 0.993062695488
223 0.993063060567
224 0.993063973263
225 0.993062876165
226 0.993063354865
227 0.993064340204
228 0.993063315749
229 0.993062369525
230 0.993063429371
231 0.993064191192
232 0.99306409806
233 0.993063297123
234 0.993063645437
235 0.993064371869
236 0.993065051734
237 0.993062082678
238 0.993062786758
239 0.993065936491
240 0.993061635643
241 0.993061222136
242 0.993064589798
243 0.993063481525
244 0.993062198162
245 0.993063278496
246 0.993064235896
247 0.993062874302
248 0.993062108755
249 0.993064120412
250 0.993063339964
251 0.993063824251
252 0.993063464761
253 0.993064682931
254 0.993062494323
255 0.993063546717
256 0.993063425645
257 0.993064461276
258 0.993061479181
259 0.993062803522
260 0.993062797934
261 0.993062797934
262 0.993062797934
263 0.993062797934
264 0.993062797934
265 0.993062797934
266 0.993062797934
267 0.993062797934
268 0.993062797934
269 0.993062797934
270 0.993062797934
271 0.993062797934
272 0.993062797934
273 0.993062797934
274 0.993062797934
275 0.993062797934
276 0.993062797934
277 0.993062797934
278 0.993062797934
279 0.993062797934
280 0.993062797934
281 0.993062797934
282 0.993062797934
283 0.993062797934
284 0.993062797934
285 0.993062760681
286 0.993063656613
287 0.993064278737
288 0.993063313887
289 0.993063293397
290 0.993063298985
291 0.993063395843
292 0.993063285947
293 0.993062391877
294 0.993063881993
295 0.993063747883
296 0.993062488735
297 0.993063895032
298 0.993063762784
299 0.993062917143
300 0.993063975126
301 0.993063671514
302 0.993063909933
303 0.993062824011
304 0.993064835668
305 0.993062773719
306 0.993062881753
307 0.993064772338
308 0.993063498288
309 0.993062434718
310 0.993064312264
311 0.993063271046
312 0.99306287989
313 0.993063544855
314 0.993063639849
315 0.99306297116
316 0.993062786758
317 0.993064923212
318 0.993062993512
319 0.993063310161
320 0.993063291535
321 0.993063371629
322 0.993063271046
323 0.993063310161
324 0.993063310161
325 0.993063310161
326 0.993063278496
327 0.993063244969
328 0.993063481525
329 0.993063222617
330 0.993063053116
331 0.993063760921
332 0.993063686416
333 0.993063347414
334 0.993062905967
335 0.99306384474
336 0.993063589558
337 0.993063431233
338 0.993063390255
339 0.993063604459
340 0.993063524365
341 0.993063524365
342 0.993063524365
343 0.993063524365
344 0.993063524365
345 0.993063524365
346 0.993063524365
347 0.993063524365
348 0.993063524365
349 0.993063524365
350 0.993063524365
351 0.993063498288
352 0.993063524365
353 0.993063524365
354 0.993063498288
355 0.993063524365
356 0.993063524365
357 0.993063524365
358 0.993063524365
359 0.993063524365
360 0.993063511327
361 0.993063455448
362 0.993063535541
363 0.993063524365
364 0.993063498288
365 0.993063565344
366 0.993063505739
367 0.993063442409
368 0.993063582107
369 0.993063768372
370 0.993062892929
371 0.993063310161
372 0.993063744158
373 0.993063747883
374 0.99306297861
375 0.99306303449
376 0.993063814938
377 0.993062706664
378 0.993064438924
379 0.993063582107
380 0.99306367524
381 0.993062976748
382 0.993063734844
383 0.993062658235
384 0.993063684553
385 0.993064263836
386 0.993062950671
387 0.993063656613
388 0.993064578623
389 0.993062764406
390 0.993063528091
391 0.99306457676
392 0.99306354858
393 0.993062624708
394 0.993063654751
395 0.993064543232
396 0.993062742054
397 0.993063475937
398 0.993064338341
399 0.993063827977
400 0.993063246831
401 0.993063326925
402 0.99306435138
403 0.993062814698
404 0.993063794449
405 0.99306287244
406 0.993063410744
407 0.993064334616
408 0.993063718081
409 0.993062796071
410 0.993063643575
411 0.993063578382
412 0.993063621223
413 0.993063967675
414 0.993064278737
415 0.993062524125
416 0.993063623086
417 0.993064533919
418 0.993063390255
419 0.993062825873
420 0.993064563721
421 0.993063032627
422 0.993062639609
423 0.99306399934
424 0.993064785376
425 0.993062913418
426 0.993062403053
427 0.993064392358
428 0.993063254282
429 0.993062909693